{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 正負情緒判斷"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "# import jieba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1112, 5)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>content</th>\n",
       "      <th>stars</th>\n",
       "      <th>title</th>\n",
       "      <th>status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>不知道耶! 看完整個無感\\r\\n有種覺得就是女兒\"給蕭\"害死了老爸\\r\\n然後...既然可以...</td>\n",
       "      <td>3</td>\n",
       "      <td>古墓奇兵</td>\n",
       "      <td>soso</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>很好看的動作片，不會浪費錢跟時間。很久沒有這樣的探險片。可說是女版的印第安那瓊。女主角跟爸爸...</td>\n",
       "      <td>5</td>\n",
       "      <td>古墓奇兵</td>\n",
       "      <td>good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>說這個不好看的話，那我還真不知道，還有什麼片是您可以去看得了。電影好看，但話說羅拉有裝可以撿...</td>\n",
       "      <td>5</td>\n",
       "      <td>古墓奇兵</td>\n",
       "      <td>good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>父女重逢真的很讓人感動，五顆星。</td>\n",
       "      <td>5</td>\n",
       "      <td>古墓奇兵</td>\n",
       "      <td>good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>劇情雖然老套，但仍拍出新意，古墓能殺人的方式不就是機關和毒，要求亂七八糟的觀眾，你看喪尸片看多了。</td>\n",
       "      <td>4</td>\n",
       "      <td>古墓奇兵</td>\n",
       "      <td>good</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                            content  stars title  \\\n",
       "0           0  不知道耶! 看完整個無感\\r\\n有種覺得就是女兒\"給蕭\"害死了老爸\\r\\n然後...既然可以...      3  古墓奇兵   \n",
       "1           1  很好看的動作片，不會浪費錢跟時間。很久沒有這樣的探險片。可說是女版的印第安那瓊。女主角跟爸爸...      5  古墓奇兵   \n",
       "2           2  說這個不好看的話，那我還真不知道，還有什麼片是您可以去看得了。電影好看，但話說羅拉有裝可以撿...      5  古墓奇兵   \n",
       "3           3                                   父女重逢真的很讓人感動，五顆星。      5  古墓奇兵   \n",
       "4           4  劇情雖然老套，但仍拍出新意，古墓能殺人的方式不就是機關和毒，要求亂七八糟的觀眾，你看喪尸片看多了。      4  古墓奇兵   \n",
       "\n",
       "  status  \n",
       "0   soso  \n",
       "1   good  \n",
       "2   good  \n",
       "3   good  \n",
       "4   good  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movies = pd.read_excel('https://raw.githubusercontent.com/ywchiu/pytextmining/master/data/yahoo_movie.xlsx')\n",
    "print(movies.shape)\n",
    "movies.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(980, 5)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>content</th>\n",
       "      <th>stars</th>\n",
       "      <th>title</th>\n",
       "      <th>status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>很好看的動作片，不會浪費錢跟時間。很久沒有這樣的探險片。可說是女版的印第安那瓊。女主角跟爸爸...</td>\n",
       "      <td>5</td>\n",
       "      <td>古墓奇兵</td>\n",
       "      <td>good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>說這個不好看的話，那我還真不知道，還有什麼片是您可以去看得了。電影好看，但話說羅拉有裝可以撿...</td>\n",
       "      <td>5</td>\n",
       "      <td>古墓奇兵</td>\n",
       "      <td>good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>父女重逢真的很讓人感動，五顆星。</td>\n",
       "      <td>5</td>\n",
       "      <td>古墓奇兵</td>\n",
       "      <td>good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>劇情雖然老套，但仍拍出新意，古墓能殺人的方式不就是機關和毒，要求亂七八糟的觀眾，你看喪尸片看多了。</td>\n",
       "      <td>4</td>\n",
       "      <td>古墓奇兵</td>\n",
       "      <td>good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>每個演員都長得像路人，劇情解謎上都沒有作一些鋪陳，以致於每個謎題只有主角轉一轉就都破解了，覺...</td>\n",
       "      <td>2</td>\n",
       "      <td>古墓奇兵</td>\n",
       "      <td>bad</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                            content  stars title  \\\n",
       "1           1  很好看的動作片，不會浪費錢跟時間。很久沒有這樣的探險片。可說是女版的印第安那瓊。女主角跟爸爸...      5  古墓奇兵   \n",
       "2           2  說這個不好看的話，那我還真不知道，還有什麼片是您可以去看得了。電影好看，但話說羅拉有裝可以撿...      5  古墓奇兵   \n",
       "3           3                                   父女重逢真的很讓人感動，五顆星。      5  古墓奇兵   \n",
       "4           4  劇情雖然老套，但仍拍出新意，古墓能殺人的方式不就是機關和毒，要求亂七八糟的觀眾，你看喪尸片看多了。      4  古墓奇兵   \n",
       "5           5  每個演員都長得像路人，劇情解謎上都沒有作一些鋪陳，以致於每個謎題只有主角轉一轉就都破解了，覺...      2  古墓奇兵   \n",
       "\n",
       "  status  \n",
       "1   good  \n",
       "2   good  \n",
       "3   good  \n",
       "4   good  \n",
       "5    bad  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movies = movies[movies['status'] != 'soso']\n",
    "print(movies.shape)\n",
    "movies.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.3.0\n",
      "cuda\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "print(torch.__version__)\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "To use data.metrics please install scikit-learn. See https://scikit-learn.org/stable/index.html\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertTokenizer, BertModel, BertForMaskedLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 109540/109540 [00:00<00:00, 256568.89B/s]\n"
     ]
    }
   ],
   "source": [
    "# Load pre-trained model tokenizer (vocabulary)\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-chinese')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 520/520 [00:00<00:00, 699050.67B/s]\n",
      "100%|██████████| 411577189/411577189 [03:01<00:00, 2271338.07B/s]\n"
     ]
    }
   ],
   "source": [
    "# Load pre-trained model (weights)\n",
    "model = BertModel.from_pretrained('bert-base-chinese')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['很',\n",
       " '好',\n",
       " '看',\n",
       " '的',\n",
       " '動',\n",
       " '作',\n",
       " '片',\n",
       " '，',\n",
       " '不',\n",
       " '會',\n",
       " '浪',\n",
       " '費',\n",
       " '錢',\n",
       " '跟',\n",
       " '時',\n",
       " '間',\n",
       " '。',\n",
       " '很',\n",
       " '久',\n",
       " '沒',\n",
       " '有',\n",
       " '這',\n",
       " '樣',\n",
       " '的',\n",
       " '探',\n",
       " '險',\n",
       " '片',\n",
       " '。',\n",
       " '可',\n",
       " '說',\n",
       " '是',\n",
       " '女',\n",
       " '版',\n",
       " '的',\n",
       " '印',\n",
       " '第',\n",
       " '安',\n",
       " '那',\n",
       " '瓊',\n",
       " '。']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tokenize input\n",
    "text = \"很好看的動作片，不會浪費錢跟時間。很久沒有這樣的探險片。可說是女版的印第安那瓊。\"\n",
    "tokenized_text = tokenizer.tokenize(text)\n",
    "print(type(tokenized_text))\n",
    "tokenized_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[2523,\n",
       " 1962,\n",
       " 4692,\n",
       " 4638,\n",
       " 1240,\n",
       " 868,\n",
       " 4275,\n",
       " 8024,\n",
       " 679,\n",
       " 3298,\n",
       " 3857,\n",
       " 6527,\n",
       " 7092,\n",
       " 6656,\n",
       " 3229,\n",
       " 7279,\n",
       " 511,\n",
       " 2523,\n",
       " 719,\n",
       " 3760,\n",
       " 3300,\n",
       " 6857,\n",
       " 3564,\n",
       " 4638,\n",
       " 2968,\n",
       " 7402,\n",
       " 4275,\n",
       " 511,\n",
       " 1377,\n",
       " 6303,\n",
       " 3221,\n",
       " 1957,\n",
       " 4276,\n",
       " 4638,\n",
       " 1313,\n",
       " 5018,\n",
       " 2128,\n",
       " 6929,\n",
       " 4475,\n",
       " 511]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert token to vocabulary indices\n",
    "indexed_tokens = tokenizer.convert_tokens_to_ids(tokenized_text)\n",
    "print(type(indexed_tokens))\n",
    "indexed_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[2523, 1962, 4692, 4638, 1240,  868, 4275, 8024,  679, 3298, 3857, 6527,\n",
       "         7092, 6656, 3229, 7279,  511, 2523,  719, 3760, 3300, 6857, 3564, 4638,\n",
       "         2968, 7402, 4275,  511, 1377, 6303, 3221, 1957, 4276, 4638, 1313, 5018,\n",
       "         2128, 6929, 4475,  511]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert inputs to PyTorch tensors\n",
    "tokens_tensor = torch.tensor([indexed_tokens])\n",
    "tokens_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "40"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "segments_ids = [0,0]\n",
    "for i in range(2, len(text)):\n",
    "    segments_ids.append(0)\n",
    "\n",
    "# Convert inputs to PyTorch tensors\n",
    "segments_tensors = torch.tensor([segments_ids])\n",
    "segments_tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input_ids = torch.tensor([tokenizer.encode(text, add_special_tokens=True)])  \n",
    "# # Add special tokens takes care of adding [CLS], [SEP], <s>... tokens in the right way for each model.\n",
    "\n",
    "# input_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[2523, 1962, 4692, 4638, 1240,  868, 4275, 8024,  679, 3298, 3857, 6527,\n",
       "         7092, 6656, 3229, 7279,  511, 2523,  719, 3760, 3300, 6857, 3564, 4638,\n",
       "         2968, 7402, 4275,  511, 1377, 6303, 3221, 1957, 4276, 4638, 1313, 5018,\n",
       "         2128, 6929, 4475,  511]], device='cuda:0')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load pre-trained model (weights)\n",
    "model = BertModel.from_pretrained('bert-base-chinese')\n",
    "\n",
    "# Set the model in evaluation mode to deactivate the DropOut modules\n",
    "# This is IMPORTANT to have reproducible results during evaluation!\n",
    "model.eval()\n",
    "\n",
    "# If you have a GPU, put everything on cuda\n",
    "tokens_tensor = tokens_tensor.to('cuda')\n",
    "segments_tensors = segments_tensors.to('cuda')\n",
    "model.to('cuda')\n",
    "tokens_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict hidden states features for each layer\n",
    "with torch.no_grad():\n",
    "    # See the models docstrings for the detail of the inputs\n",
    "    outputs = model(tokens_tensor, token_type_ids=segments_tensors)\n",
    "    # Transformers models always output tuples.\n",
    "    # See the models docstrings for the detail of all the outputs\n",
    "    # In our case, the first element is the hidden state of the last layer of the Bert model\n",
    "    encoded_layers = outputs[0]\n",
    "# We have encoded our input sequence in a FloatTensor of shape (batch size, sequence length, model hidden dimension)\n",
    "assert tuple(encoded_layers.shape) == (1, len(indexed_tokens), model.config.hidden_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jieba.load_userdict('userdict.txt')\n",
    "corpus = []\n",
    "scores = []\n",
    "for movie in movies.iterrows():\n",
    "    corpus.append(' '.join(jieba.cut(movie[1].content)))\n",
    "    scores.append(movie[1].status)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "vectorizer = TfidfVectorizer()\n",
    "X = vectorizer.fit_transform(corpus)\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train_X, test_X, train_Y, test_Y = train_test_split(X, scores, test_size = 0.3, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "train_X.shape, test_X.shape, len(train_Y), len(test_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "clf = MultinomialNB(alpha = 0.01)\n",
    "clf.fit(train_X, train_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted = clf.predict(test_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(test_Y, predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "print(clf.classes_)\n",
    "confusion_matrix(test_Y, predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "import operator\n",
    "coef_features_c1_c2 = []\n",
    "\n",
    "for index, features in enumerate(zip(vectorizer.get_feature_names(), \\\n",
    "                        clf.feature_count_[0], clf.feature_count_[1])):\n",
    "    feat,c1,c2 = features\n",
    "    coef_features_c1_c2.append(tuple([c2/(c1 + 1), feat, c1, c2]))\n",
    "\n",
    "for i in sorted(coef_features_c1_c2, key = operator.itemgetter(0), reverse=True)[0:20]:\n",
    "    print(i)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "import operator\n",
    "coef_features_c1_c2 = []\n",
    "\n",
    "for index, features in enumerate(zip(vectorizer.get_feature_names(), \\\n",
    "                        clf.feature_count_[0], clf.feature_count_[1])):\n",
    "    feat,c1,c2 = features\n",
    "    coef_features_c1_c2.append(tuple([c1/(c2 + 1), feat, c1, c2]))\n",
    "\n",
    "for i in sorted(coef_features_c1_c2, key = operator.itemgetter(0), reverse=True)[0:20]:\n",
    "    print(i)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_comment = '非常精彩值得一看 劇情豐富 出乎意料'\n",
    "new_vec = vectorizer.transform([' '.join(jieba.cut(new_comment))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "clf.predict(new_vec)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
